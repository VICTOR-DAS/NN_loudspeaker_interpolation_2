{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "\n",
    "class PatchEmbedding(layers.Layer):\n",
    "    def __init__(self, patch_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.projection = layers.Conv2D(embed_dim, kernel_size=patch_size, strides=patch_size)\n",
    "        self.flatten = layers.Reshape((-1, embed_dim))\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.cast(x, tf.float16)\n",
    "        patches = self.projection(x)\n",
    "        flattened = self.flatten(patches)\n",
    "        return tf.cast(flattened, tf.float16)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"patch_size\": self.patch_size,\n",
    "            \"embed_dim\": self.embed_dim\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.dropout_rate = dropout\n",
    "        \n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(ff_dim, activation=\"gelu\"),\n",
    "            layers.Dense(embed_dim),\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(dropout)\n",
    "        self.dropout2 = layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = tf.cast(inputs, tf.float16)\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = tf.cast(attn_output, tf.float16)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = tf.cast(ffn_output, tf.float16)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"ff_dim\": self.ff_dim,\n",
    "            \"dropout\": self.dropout_rate\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class VisionTransformer(layers.Layer):\n",
    "    def __init__(self, num_heads=8, embed_dim=256, ff_dim=2048, \n",
    "                 num_transformer_blocks=6, window_size=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.embed_dim = embed_dim\n",
    "        self.ff_dim = ff_dim\n",
    "        self.num_transformer_blocks = num_transformer_blocks\n",
    "        self.window_size = window_size\n",
    "        self.dropout_rate = dropout\n",
    "        \n",
    "        # Definir dimensiones de la imagen y patches\n",
    "        self.img_height = 2664\n",
    "        self.img_width = 44\n",
    "        self.patch_size = (36, 4)\n",
    "        self.num_patches = (self.img_height // self.patch_size[0]) * (self.img_width // self.patch_size[1])\n",
    "        \n",
    "        # Inicializar capas\n",
    "        self.patch_embed = PatchEmbedding(self.patch_size, embed_dim)\n",
    "        self.position_embed = layers.Embedding(self.num_patches + 1, embed_dim)\n",
    "        self.cls_token = tf.Variable(tf.zeros([1, 1, embed_dim], dtype=tf.float16))\n",
    "        \n",
    "        # Crear bloques transformer\n",
    "        self.transformer_blocks = [\n",
    "            TransformerBlock(embed_dim, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_transformer_blocks)\n",
    "        ]\n",
    "        \n",
    "        # MLP head\n",
    "        self.mlp_head = tf.keras.Sequential([\n",
    "            layers.Dense(ff_dim, activation='gelu'),\n",
    "            layers.Dropout(dropout),\n",
    "            layers.Dense(self.patch_size[0] * self.patch_size[1])\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = tf.cast(inputs, tf.float16)\n",
    "        x = self.patch_embed(inputs)\n",
    "        \n",
    "        batch_size = tf.shape(x)[0]\n",
    "        cls_tokens = tf.cast(tf.repeat(self.cls_token, batch_size, axis=0), tf.float16)\n",
    "        x = tf.concat([cls_tokens, x], axis=1)\n",
    "        \n",
    "        positions = tf.range(start=0, limit=self.num_patches + 1)\n",
    "        position_embeddings = tf.cast(self.position_embed(positions), tf.float16)\n",
    "        x = x + position_embeddings\n",
    "        \n",
    "        for transformer_block in self.transformer_blocks:\n",
    "            x = transformer_block(x)\n",
    "        \n",
    "        x = x[:, 1:, :]\n",
    "        x = self.mlp_head(x)\n",
    "        \n",
    "        final_h = self.img_height\n",
    "        final_w = self.img_width\n",
    "        \n",
    "        x = tf.reshape(x, [-1, final_h // self.patch_size[0], \n",
    "                          final_w // self.patch_size[1], \n",
    "                          self.patch_size[0] * self.patch_size[1]])\n",
    "        \n",
    "        x = tf.reshape(x, [-1, final_h, final_w, 1])\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"ff_dim\": self.ff_dim,\n",
    "            \"num_transformer_blocks\": self.num_transformer_blocks,\n",
    "            \"window_size\": self.window_size,\n",
    "            \"dropout\": self.dropout_rate\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # Extraer solo los argumentos que necesitamos\n",
    "        vit_config = {\n",
    "            'num_heads': config.get('num_heads', 8),\n",
    "            'embed_dim': config.get('embed_dim', 256),\n",
    "            'ff_dim': config.get('ff_dim', 2048),\n",
    "            'num_transformer_blocks': config.get('num_transformer_blocks', 6),\n",
    "            'window_size': config.get('window_size', 256),\n",
    "            'dropout': config.get('dropout', 0.1)\n",
    "        }\n",
    "        return cls(**vit_config)\n",
    "\n",
    "def create_vit_model(input_shape):\n",
    "    # Configurar la política de precisión mixta\n",
    "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "    \n",
    "    # Crear el modelo\n",
    "    inputs = Input(shape=input_shape, dtype=tf.float16)\n",
    "    vit = VisionTransformer(\n",
    "        num_heads=8,\n",
    "        embed_dim=256,\n",
    "        ff_dim=512,\n",
    "        num_transformer_blocks=6,\n",
    "        window_size=256,\n",
    "        dropout=0.1\n",
    "    )\n",
    "    outputs = vit(inputs)\n",
    "    return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Uso del modelo\n",
    "if __name__ == \"__main__\":\n",
    "    model = create_vit_model(input_shape=(2664, 44, 1))\n",
    "    print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Crear el modelo\n",
    "model = create_vit_model(input_shape=(2664, 44, 1))\n",
    "\n",
    "# Ver el resumen del modelo\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
